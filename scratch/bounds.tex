\documentclass{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{stmaryrd}

\newcommand{\union}{\cup}
\newcommand{\inter}{\cap}
\newcommand{\Dpmi}{\Delta^{\min}_+}
\newcommand{\Dpma}{\Delta^{\max}_+}
\newcommand{\Dmmi}{\Delta^{\min}_-}
\newcommand{\Dmma}{\Delta^{\max}_-}
%\newcommand{\deg}{\mathrm{deg}}

\begin{document}

\subsection*{Max-cut}

The elements are processed as in a serial order. We here look at the cost of a single graph node $i$, and later sum over all nodes. For simplicity, for the moment we assume that all edges have the same weight.

We have an arbitrary permutation of the elements. We use the following notation:

\begin{itemize}
\item Let $C$ be the batch of $c$ nodes immediately preceding $i$ -- this is an upper bound on the elements that are processed in parallel with $i$, and for which we do not have any local accurate informaion at the time $i$ is processed.
\item Let $U$ be the set of elements that are as yet unprocessed when visiting $i$, i.e., the elements that succeed $i$ in the serial order.
\item Let $A$ be the set of elements preceding $i$ that have been selected;
\item Let $R$ be the set of elements preceding $i$ that have not been selected.
\item Let $w_i(C)$ be the number of edges from $i$ to $C$.
\end{itemize}
So $V = A \union R \union \{i\} \union C \union U$.

By Xinghao's analysis, we have the bound
\begin{align}
  P(i \text{ validated}) &\leq \frac{\Dpma}{\Dpma + \Dmmi} - \frac{\Dpmi}{\Dpmi + \Dmma} \leq \min\{ 1, \frac{w_i(C)}{w_i(U)} \leq w_i(C).
\end{align}
We may upper bound the above by either $1_{w_i(C) > 0}$ or $w_i(C)$.
Of course, $w_i(C)$ and $w_i(U)$ depend on the order in which elements are presented. We assume each permutation to be equally likely.

Let us fix a position for $i$. The same analysis will hold for each position of $i$, and we can then simply average.
The expected number of elements falling into the bin $C$ directly preceding $i$ is then the expected number -- out of $w_i(C)$ neighbors of $i$ -- that occur on $C$ when we randomly assign them to positions in an array of $n-1$ positions.
There are ${ w_i(C) \choose k}{n-1 \choose c - k}c!$ ways to choose $k$ neighbors of $i$ and $c-k$ non-neighbors and arrange them in positions in $C$. There are $(n-1-c)!$ ways to arrange the remaining elements. Hence, the probability of exactly $k$ neighbors falling into $C$ is
\begin{align}
  P( C \inter \mathcal{N}(i) = k) = \frac{1}{(n-1)!}{ w_i(C) \choose k}{n-1 \choose c - k}c! (n-1-c)!
\end{align}
The expected number of neighbors in $C$ is then (averaging over the $n$ possible positions of $i$
\begin{align}
  \mathbb{E}[ w_i(C) ] \leq \frac{n}{n} \sum_{k=0}^{w_i(C)} {n-1 \choose c}^{-1}{ w_i(C) \choose k}{n-1 \choose c - k} k = \frac{c \cdot \deg(i)}{n},
\end{align}
using the expectation of the hypergeometric distribution.
Averaging over all nodes gives the average degree:
\begin{align*}
  \sum_{i \in V} \mathbb{E}[ w_i(C^i) ] \leq   \sum_{i \in V} \mathbb{E}[ w_i(C) ] = \sum_{i} \frac{c\cdot \mathrm{deg}(i)}{n}.
\end{align*}

If we use 1 as the upper bound, we obtain
\begin{align*}
  \mathbb{E}[ \llbracket w_i(C) > 0 \rrbracket ] &= P(  \llbracket w_i(C) > 0 \rrbracket ) \\
  &\leq 1 - {n \choose c}^{-1} {n-\deg(i) \choose c}.
\end{align*}
If $\deg(i)$ is small in comparison to $n$, then this is hopefully small.





\end{document}
